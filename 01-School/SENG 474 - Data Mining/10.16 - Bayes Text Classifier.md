## Bernoulli Model
N: number of documents
$N_c$: number of documents in class $c$
$N_{c,t}$: number of documents in class $c$ with term $t$
$P(c)=\frac{N_c}{N}$
$P(t|c)=\frac{N_{c,t}}{N_c}$ 

how do we classify a new document d? Remember the formula from Naive bayes
the chance the document d is in class c is:
alpha 
\* the probability of any document being in the class c 
\* the product of the probability of containing a term given any class
\* the probability any class doesn't have that term
$$P(c|d)=\alpha{}P(c)\Pi_{t\in{}d}P(t|c)\Pi_{t\notin{}d}(1-P(t|c))$$
$$C_{map}=argmax_cP(c|d)$$

#### Example:
![[Pasted image 20241016172630.png]]
P(c=china)=3/4, P(-c=china)=1/4
P(Chinese|c)=(3+1)/(3+2)=4/5
P(Chinese|-c)=(1+1)/(1+2)=2/3
P(Tokyo|c)=1/2
P(Tokyo|-c)=2/3
P(Japan|c)=1/2
P(Japan|-c)=2/3

P(c|d5)=P(c)\*P(chinese|c)\*P(japan|c)\*(1-p(Beijing))\*(1-P(Shanghai))\*(1-P(Macao))

we can simplify and get an alpha value of 0.005
multiply it all together, and the predictor says it's not about china.
![[Pasted image 20241016173222.png]]
The problem with this is that it weighs the words Tokyo and Japan far too heavily.
### Multinomial model
 $T_{c,t}$: number of occurrences of t in documents in class c
 $P(t|c)$=number of terms $t$ divided by number of total terms in $c$

$$P(c|d)=\alpha{}*P(c)*\Pi_{t\in{}d}P(t|c)$$
classification result:
$$c_{map}=argmax_CP(c|d)$$
we want to find a c that maximises the probability of that document

![[Pasted image 20241016173715.png]]
P(c)=1/4
P(Chinese|c)=(5+1)/(8+6)=1/14

P(c|d)=
$\alpha$
\* P(c=china)
\* P(t=china|c)
\* P(c=Tokyo|c)
\* P(c=japan|china)
![[Pasted image 20241016174219.png]]
