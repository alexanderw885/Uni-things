A user has rated a number of movies, how can we find similar users to them?

Often times many values are zero, so we have a sparse matrix. We store it using either dictionaries or hash tables.

We calculate the euclidean distances between the two users. Given 2 vectors $x_1,...,x_m$ and $y_1,...,y_m$, the distance can be calculated with:
$$sim_{x,y}=\sqrt{\sum_{i=1}^m(x_i-y_y)^2}$$
This method can be good, but isn't perfect. Users who rate similar movies, for example, but one user rates higher than the other will have far euclidean distance. 

Another method is to use cosine similarity, to see if two vectors have similar angles
$$sim_{x,y}=cos\theta=\frac{x\cdot{}y}{||x||*||y||}$$
This can still get confused if two users rank the same movies but like different movies a bit more.

A way to get around this is to use:
## Pearson Correlation
we find the cosine similarity of x' and y', where:
$$x'=[1-x_1,2-x_2,...,m-x_m]$$

$$sim_{x,y}=cos\theta=\frac{x'\cdot{}y'}{||x'||*||y'||}$$
### How do we use similarity?
we find the ratio of all pairs of users who both rated the same thing.
$$\hat{r}_{u,i}=\frac{\sum_{v\in{}U_i}r_{v,i}\cdot{}sim_{u,v}}{\sum_{v\in{}U_i}sim_{u,v}}$$
$u$ is user, $U$ is the set of all users
$i$ is the item

We can also find similar items to each other
$$\hat{r}_{u,i}=\frac{\sum_{j\in{}I_u}r_{u,j}\cdot{}sim_{i,j}}{\sum_{j\in{}I_u}sim_{i'j}}$$
It's the same as similar users, we just sum through all the items in $I$ that the user $u$ rated, instead of all the users.
This predicts what user $u$ would rate item $i$.

This method, Pearson Correlation, is very robust compared to the other methods, even when users don't rate many items. 
When comparing users, we tend to get diversified recommendations, but unusual users will not get very good recommendations.
When comparing items, it's very good at identifying similar items, and unusual users will get better recommendations.

How do we tell if a model is good? We compute the root mean square error RMSE
$$RMSE=\sqrt{\frac{\sum_{u\in{}U,i\in{}I}(r_{u,i}-\hat{r}_{u,i})^2}{N}}$$
find the square of all the error from the estimated to actual $r$ values, divide by the number of combinations evaluated, and then take the square root.

___
Netflix held a competition to improve the recommendation system in 2009, the competition was worth $1,000,000.

They used gradient descent to minimize the RMSE.

the estimated $\hat{r}_{u,i}=\mu+b_u+b_i$, where $b_u$ was the average difference between the user ratings and the mean ratings, $b_i$ was the difference between item ratings and mean ratings. They used gradient descent to find the best fitting $b_u,b_i$.
![[Pasted image 20241104174023.png]]

To improve this method, you can add "latent factors", characteristics of users and items. These user and item factors can be mapped into the same factor space, and nearby items should be recommended to users.
Again, use gradient descent
![[Pasted image 20241104174541.png]]
all of the $\lambda$ values are to reduce the weight of parameters, in order to reduce overfitting.

