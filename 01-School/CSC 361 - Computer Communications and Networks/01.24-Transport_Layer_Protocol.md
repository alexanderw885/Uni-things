## Transport Layer Services

Transport layer provides logical communication between applications running on different hosts.
There's two protocols for internet communication: TCP and UDP

Sender:
- passed an application message
- divides the message into segments
- determines segment header field values
- passes the segment to IP

Receiver:
- receives segment from IP
- checks header values
- *demultiplexes* message up to application, through a socket.


Network layer services move packets from one end-host to another, possibly through multiple intermediate routers
### Transport layer protocols:
TCP:
- reliable
- in-order delivery
- flow control
- connection setup
UDP:
- unreliable
- unordered delivery
- less overhead
No transport protocols can give guarantees about either delay or bandwidth.

___
## Multiplexing and demultiplexing

Let's say there's two sockets connecting the application layer and transport layer, both sending requests to different servers. Likewise, each server is receiving input from multiple different clients.
The transport layer has to multiplex all the messages when sending, and then demultiplex them on the receiving end.

### Demultiplexing
Host receives IP datagrams, each with a source IP, destination IP. Each datagram carries one transport-layer segment. Each segment has a source port number, and a destination port number.
The host will use both IP addresses and both port numbers to direct each segment to the correct socket.

### Internet checksums
detect errors/flipped bits in a transmitted segment
One way to do this is:
- treat contents of UDP segment as a sequence of 16-bit ints
- add these ints together
- take 1's complement, use this complement as the checksum

___
# TCP
### Overview
multiple types:
- point-to-point: one sender, one receiver
- byte stream: reliable, in order, no "message boundaries"
- full duplex data: bi-directional data flow, has MSS (maximum segment size). Internet MSS is 1500 bytes.

![[Pasted image 20250129114654.png]]

#### Go-Back-N
Sender: sends up to N consecutive packets all at once, without waiting for an ACK. Once N packets have been sent without getting an ACK, sender waits until an ACK is received before sending any more.
It's like there's a "window" that's N-wide, of how many packets can be sent without receiving an ACK. 
![[Pasted image 20250129120157.png]]
receiver: ACK every packet received in order. If a packet is missed, do not ACK anything after that packet until it's received. If, for example, packet 3 is lost, the receiver will keep sending ACK 2, saying "two is the latest packet I've received".
The receiver can return a cumulative ACK(n), which ACKs every packet up to n.
![[Pasted image 20250129120526.png]]
#### Selective repeat
sender pipelines packets, sends multiple without waiting for an ACK, has a window of size N that it can send packets in, with the window starting at the earliest packet without an ACK.
receiver will individually ACK each packet.

If the sender goes too long without receiving an ACK for a packet, it'll re-send it.
![[Pasted image 20250131113257.png]]
It's very similar to G-Back-N, but there isn't the requirement for packages to be received in order.

### TCP Flow Control
what happens if the sender is sending faster than the receiving application can read? If the receiver can't clear the socket buffer fast enough, data that overflows the buffer is lost. How can we avoid this?
Let's look at the packet format again
![[Pasted image 20250129114654.png]]
the packet includes the receive window, the receiver sets it to limit how much the sender will send.
The TCP receiver shares the free buffer space in the receive window (`rwnd`) field. Buffer size is set with socket options.
Once the sender receives `rwnd`, it ensures that unACKed packets do not total to more space than allowed. This guarantees that the buffer will not overflow.
### Congestion control
Now it's not just one sender sending too much, there's too many sources that altogether send too much data for the *network* to handle. This leads to both long delays due to queuing, and packet loss from buffer overflow. It's a very large and important problem in networking.
![[Pasted image 20250207115801.png]]
As average input rate reaches the max output rate, throughput gets capped. If a router is receiving packets faster then it can send them, delay due to the queue tends toward infinity, assuming infinite buffer size. In reality, this means packets will be lost.

In this case, the sender will decide the window size `cwind`. How does it decide the window size?
one method is AIMD
Additive increase: keep increasing window size by 1 every RTT until a loss is detected
Multiplicative decrease: divide window size by two once a loss is detected. If a loss is detected by timeout, cut the window size to 1

TCP Slow start
alternative to AIMD
until the first loss, we increase `cwind` exponentially. Start with 1, and every RTT double it. could also be thought of as "increase `cwind` by 1 for every ACK received"
On any loss event, we set the `sshthresh` to half of the previous `cwind` and set `cwind` to 1
any time `cwind` is below `sshthresh`, it increases exponentially.
any time it's above `sshthresh`, it increases linearly.