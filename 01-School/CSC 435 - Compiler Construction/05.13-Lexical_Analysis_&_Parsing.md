How can you define a programming language? 
This is a hard problem, and no single framework can solve it. Instead of that, we break it into layers, each of which has suitable language for the task it's in charge of. 
It can be compared to "letters","words", and so on:
- let's start with the set of "letters" in a language. 
- Each "word" is a sequence of letters, it has a start, end, and an order. 
- each "sentence" is a sequence of words


Lexical analysis:
convert the input data into tokens, to make the parser's job easier. This is hard to make by hand, so we use a lexer generator. In this class, we use `ANTLR`, but there's also `lex`, `flex`, and `Jflex`. They take in an input file that specifies the structure, and converts the input data into tokens.

**Note:** "language" in this course uses the CSC330 formal definition, the set of all strings belonging to a language. L('a')={"a"}, or 
L("a$^+$")  = {"a", "aa", "aaa", ... }

![[Pasted image 20250513125407.png]]
Note that s$^?$ means either 0 or 1 of s.
Examples:

| In Ceelish                         | Regex                           |
| ---------------------------------- | ------------------------------- |
| print keyword                      | `"print"`                       |
| any `id`                           | ([a-z]\|\_)([a-z]\|[0-9]\|\_)\* |
| any `floatconstant`                | [0-9]+\.[0-9]+                  |
| a string in python of only letters | ('[0-9]\*')\|("[0-9]\*")        |

We can construct an automaton to recognize the language, like in CSC320. How do we do this?
Start by building a nondeterministic finite automata (NFA). We need to do this so we can use $\epsilon$ transitions.
Once we've made an NFA, how do we convert it into a DFA?
We create a DFA, where each state is a combination of states in the NFA. The total set of states in the DFA is the power set of states in the NFA

**Homework**: Make DFA for a\*(a|b)aa

The lexer, or scanner, transform the input letters/characters into a sequence of tokens. These tokens get passed into the parser for semantic analysis. The parser is like a DFA, or finite automaton.

Most of the time, parsing uses a context-free grammar,  though they can be context-sensitive in some cases.
It outputs a form of intermediate representation, though often not *the* IR. it's usually a syntax tree, that then needs to be walked through in order to get the actual IR.

Grammars are often written using [Extended Backus-Naur Form](01.15-Syntax_Semantics)

Just like discussed in CSC330, there can be cases where there can be multiple syntax trees for the same parse string. If we do a leftmost derivation or rightmost derivation, the final result may be different. How might we prevent this?
Precedence. 
![[Pasted image 20250520123543.png]]
Note that in this case, addition and subtraction much happen higher up in the tree, with multiplication and division lower. This enforces order of operations/precedence, and constrains the result so that no matter if you use leftmost or rightmost derivation, you always get the same result.

**Ambiguity in grammar**
`if E1 then if E2 then S1 else S2
what does the else connect to?
python examples:
```python
# solution 1
if E1:
	if E2:
		S1
	else:
		S2

# solution 2
if E1:
	if E2:
		S1
else:
	S2
```
the general procedure in this case would be solution 1. *Match an else statement with the closest if statement*.
In general, we can reflect this by adding a `matched` and `unmatched` to the grammar:
![[Pasted image 20250520130048.png]]
However, there are still cases where this does not work.

### Parsers
#### Top Down
start at the root of derivation tree, and work down.
Backtracking may be required, and we continue until the "fringe", all the leaves, match the input string in an in-order traversal.
Top down parsers **Cannot** handle left-recursion, if doing a leftmost derivation.
![[Pasted image 20250521123552.png]]
`<expr> := <expr> + <term>` causes the parser to get stuck in a recursion loop. We can solve this by 
transforming the grammar. Start with the following grammar fragment:
```
<foo> ::= <foo>a
        | b
```
we can write this grammar as b+a\*
assuming both a and b do not start with `<foo>`, we can transform it to:
```
<foo> ::= b<bar>
<bar> ::= a<bar>
	   | epsilon
```

Let's look at a real-world example:
```
<term> ::= <term> * <factor>
		 | <term> / <factor>
		 | <factor>
```
`<term>` is like `<foo>` in the example
`* <factor>` and `/ <factor>` are `a`
and `<factor>` is beta

We can transform it into: 
```
<term> ::= <factor> <term'>
<term'> ::= * <term'>
		  | / <term'>
		  | epsilon
```

Another method would be to add rightmost recursion instead. This does solve the problem, but it add right-associativity, which might not be desirable.


The parser we've talked about need backtracking. This works, but surely there's a better way, and there is! By adding lookahead, we can reduce or remove backtracking.
- LL(1): left-to-right scan, leftmost derivation, one token of lookahead
- LR(1): left to right scan, *rightmost* derivation, one token lookahead.

Let's look at LL(1).
let's say we have the rule A -> a | b.
What we want to be able to do is tell right away whether a or b is the correct choice.
let's define FIRST(a): FIRST(a) is the set of all possible leftmost tokens derived from a. If we choose a, whatever the first character in that string is, it's in FIRST(a).
the key property we need is the following:
$FIRST(a)\cap{}FIRST(b)=\emptyset$ 

Can we convert any grammar into this format? It's actually undecidable if any given grammar has an equivalent that follows these rules. However, for the languages we're interested in, this should always be possible.
### Recursive Descent Parsers
Given a grammar that can support one-symbol lookahead, we can write a non-backtracking recursive parser using a stack.

Recursive parsers work, but they aren't perfect. 
### Non-recursive Predictive Parsing
These use table-driven parsers. These table-driven-parsers take inputs from a parsing table, the current stack state, and tokens from the parser/lexer.
Ideally, we just create the language grammar, put that into a parser generator, and then the generator will create the parser tables. ANTLR4 is the parser generator we'll be using. 
We start with the starting non-terminal in the stack. 
then, we use the next token from the parser and the terminal or non-terminal on the stack to look up a value in the parser tables. 
Next, put the terminals and non-terminals from the table onto the stack.

- Look at top of stack:
	- if it's a terminal, compare to the next token
		- if they match, pop off top of stack and advance to the next token. 
		- Else, error
	- if it's a non terminal, use that and next token to look up value in parser table
		- if new terminals and non-terminals are found, push them onto stack *in reverse order* (end-of-file counts as a token, `$`)
		- Else, error
	- if the stack is empty:
		- if the next token is end-of-file, we're done!
		- Else, error
- Repeat until done


how do parse tables look?
each row is a non-terminal
each column is a token.
