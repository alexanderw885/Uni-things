Recall from the [intro](05.07-Intro) that compilers have a front end and a back end. Modern compilers also have a middle end, but we won't worry about that right now.

Intermediate code generation is the end of the front end. We send the intermediate representation (IR) from the front end to the back end. This lets us decouple these two ends, meaning we could, for example, just write the front end for a language compiler and have it use a pre-existing backend. We could even write multiple back ends, one for each architecture. With this, any new language only needs a new front end to be compatible with every architecture, and and new architecture only needs a new back end to be compatible with any language

`gcc`, as an example, is a collection of backends that all share a common IR. This is what lets it produce x86 code, ARM code, assembly, and more!

`gcc file -o out -fdump-tree-gimble` actually returns a high-level IR

Instead of a proper backend, we can even send the IR to an interpreter.

___
Do we want a high level or a low level IR?
- High level or low level?
- High level IR is semantically closer to the source language
- Low level IR has much simpler instructions
- High level IR means a much simpler front end, and a complex low end
- Low level IR means a much simpler back end, but a more complex high end.
- High level IR can lead to lower quality machine code
**There is no right answer,** it all depends on the designers choice and the context the language is made in/for
As mentioned above, `gcc` uses a high level IR

`gcc file -o out -fdump-tree-gimble` returns a high-level IR
`gcc file -o out -da` returns a low-level IR.

As you can see, the high level IR is readable, while the low level IR is *not* meant to be read. It's very large, and very dense.

### Forms of IR
not all IRs are linear like assembly.
#### Graphical IRs
uses a graph or a tree. In order to represent this type of IR with text, you actually do use a graph.
Does a good job at capturing control flow
What do we base this graph off of?
- Parse tree: very easy to generate the IR during the parse, but not always possible
- AST: moderately easy during the parse, but that's already a large and difficult step
- Directed acyclic graph: easier in functional languages, but functions with side effects are hard to represent. This isn't directly based on any pre existing tree, but does a very good job representing repeated statements and control flow.

The most important graph format is the control-flow graph (CFG, but not context-free grammar). It's not technically an IR, but it's still useful
- Vertices are basic blocks, each using a linear IR form. They are the largest groups of code that must be traversed from beginning to end
- directed edges connect blocks to show possible control flow.
![[Pasted image 20250625130743.png]]

Alongside the IR, we'll also generate a dependency graph. This stores when/where values are created, and what data depends on what other data.
#### Linear IRs
Similar to assembly, or a pseudo code
#### Hybrid IRs

___
#### Single Static Assignment
go-to IR for many compilers in the 2000s. Has two big ideas:
1. IR variables are only defined once
2. Where multiple IR definitions for the source-code variable could be used, they're merged with a phi function
example:
```
x = 1;
x = x + 1;
```
is translated to:
```
x_1 = 1;
x_2 = x_1 + 1;
```

or, with branching control flow:
```
if(cond)
	x = 1;
else
	x = 2
```
becomes
```
# TODO: Add if/else code
x_3 = phi(x_1, x_2)
```

GCC actually uses SSA as it's ir
`gcc -c -00 code.c -fdump-tree-ssa`

### Generating IR from the AST
- We're gonna be using a lot of temporary variables, there's no limit to how many we can make.
- we recursively walk the AST
- we translate each function separately
- we output a text file
___
With each type, we put them onto the stack, and use a stack frame to access them. However, we need to keep in mind the size of each type we store. A char might not be the same size as a float
![[Pasted image 20250704124135.png]]
### Arrays
#### 1 dimensional arrays
it's quite easy to arrange these elements for access
the element `Arr[i]` is at address `Arr + (i * E)`, where `E` is the size of the type of element in the array
#### 2 Dimensional arrays
covered in [CSC330](02.07-Names-Bindings_Scopes_Datatypes)
Rectangular arrays can either be:
- row-major ordering, stores each row in order. 
	`A[1][1],..., A[1][n], A[2][1],...,A[2][n]`
- column-major ordering, which stores the first of each row, then second, and so on
	`A[1][1],...A[n][1],A[1][2],...,A[n][2]`
	Not as common, only mainstream languages that use it are Julia, R, and Fortran

Jagged arrays are arrays of arrays. The main array contains references to each sub-array
![[Pasted image 20250704124635.png]]
`A[i][j]` would be the address at `A[i]`, and then add `j*E`.

#### n-dimensional Arrays
We can generalize row major to n-dimensions.
`A[s1,s2,s3]`, for example, would count all the `s3` values, then `s2`, then `s1`
`A[2][3][2]` = `Arr ((2 * s1 * 3) * 2 + s3)*E
As we generalize, we can eventually get to this scary looking formula: To find the address of an element at 
$A[X_0,X_1,...,X_{n-1}]$
![[Pasted image 20250704125336.png]]

Choosing row major or column major has implication for cache hits.

### Switch statement
let's assume that all labels for the switch statement are known at compile time. How might we convert a switch statement into an IR?
Factors to consider:
- How many labels?
- how dense are they? (3,4,5 vs 5,20,53)
#### Linear search
glorified if else if else ...
We don't care about how dense the labels are, we just go through them linearly. It's ideal to have most common cases higher up, that that requires runtime knowledge so it can't be done at compile time. That's good for the programmer though.
![[Pasted image 20250704131045.png]]

Another linear approach is a separate `GOTO` for each case"
![[Pasted image 20250704131124.png]]
#### Non-linear searching
It can take a long time to find the right case for linear searches, so they aren't often used in practice.
A binary tree search is a good solution, but we can also implement it as a table, called `tableswitch`. The expression provided is the index in a table to a GOTO statement

What if the values are too sparse to justify a lookup table? We'd use a `lookupswitch` instead. We'd use each switch value like the key to a `dict`
