![[Pasted image 20251007103522.png]]

$A$ is the $n\times{}n$ matrix of all $a$ values
$x$ and $b$ are the column vectors, each with length $n$

the $i^{th}$ row of the entire equation $Ax+b$ is called $E_i$.
There are three operations you can perform without changing the solution
1. Multiply any row $E_i$ by a non-zero constant $\lambda$
2. add $E_i=E_i+\lambda{}E_j$
3. swap any two equations $E_i,E_j$

# Naive Gaussian Elimination
With naive Gaussian Elimination, we only use the second operation, $E_i=E_i+\lambda{}E_j$.

Using this, we want to do the two following goals:
1. Reduce $A$ to upper-triangular form. This is **forward elimination**
2. Solve for $x$: **back substitution**

Each value on the diagonal is called a **pivot**. let's take the first column, the first step in reducing. We subtract some constant times the first row from every other row, so they all have zeroes in the first column except for row 1.
Then, don't touch row one again, and repeat for row 2.
Keep going until you've gone through every column to get upper triangular form.

This is a simple algorithm, with simple code:
first, we do forward elimination to get the matrix into the right form:
![[Pasted image 20251007110858.png]]

Then, back substitution to calculate $x$:
![[Pasted image 20251007110947.png]]
# Partial Pivoting
One problem with Naive Gaussian elimination is that if any of the pivots values $a_{11},a_{22},...,a_{nn}=0$, the whole algorithm fails. 
Due to floating point arithmetic, it also breaks down if the pivots are close to 0.

To avoid these situations, we use partial pivoting. Instead of choosing whatever value is there for the pivot, we choose the value in that column with the greatest magnitude, positive or negative. Swapping rows is a valid operation, so we swap that row into the correct place.

The code for this is also quite simple:
![[Pasted image 20251015104711.png]]
Then proceed with the back substitution as we did earlier.

### Scaling
When some magnitudes on different rows differ too much, you can multiply rows by some constant in order to reduce floating point error.

There's two methods:
1. **Equilibriation**: Scale each row so that the largest value is equal to 1. You can do this by dividing each row by the largest value it contains. This can work, but division is computationally expensive, and this does quite a bit.
2. **Scaled Factors**: Calculate the same scale factor as in equilibriation, 1 over the largest value for each row. But, instead of multiplying it  over each row, just look at what the pivots would be *if you did* multiply them. Then, choose the row with the largest scaled pivot as the next row.
### Determinants
