A problem whose exact solution can change greatly with small changes in the data is called ill-conditioned.
An example would be $\frac{x}{1-x}$ for $x$ values near 1.

given data $d_i$, and a solution $r_i$: 
$$d_i\rightarrow{}r_i$$
and if there's a small error in the data:
$$d_i+\epsilon{}_i\rightarrow{}\hat{r}_i$$
where $|\frac{\epsilon_i}{d_i}|$ is small
if $r_i$ is not near $\hat{r}_i$, the problem is ill conditioned
if they *are* near, the problem is well conditioned.

Another way to analyze the condition of a problem is the condition number. This only works for differentiable functions.
for some value $x$, and a nearby value $\tilde{x}$:
$$condition\space number=\frac{\tilde{x}f'(\tilde{x})}{f(\tilde{x})}$$
If this condition number is large, the function is ill conditioned around $x$.

___
A computation is numerically unstable if uncertainty in data is greatly magnified by the numerical method.

This is often a problem due to floating point or computational uncertainty, along with any uncertainty in data collection.

There's no consistent or universal way to deal with these problems. Messing with matrices, or changing subtractions can help, but it needs to be solved in a case-by-base basis