#### Terms
- Syntax: form or structure of the expressions, statements, and program units in a language
- Semantics: meaning of the expressions, statements, and program units
Together, the syntax and semantics form the definition of a programming language. This definition used by both language designers and implementers. Sometimes programmers using the language might use the definition to help them understand the language.

- Sentence: string of characters, over some alphabet (a full computer program)
- Language: a set of legal sentences
- Lexeme: the lowest level syntactic unit of a language (keywords, `sum, with, *, +`)
- Token: category of lexemes. Could be a lexeme, could be a variable,... (not necessarily unique)
- Language recognizers: read input strings in the alphabet of a language, decides if string belongs to the language (syntax analysis in a compiler)
- Language generators: generates valid sentences for a language. More theoretical than a recognizer.
### Backus-Naur Form (BNF)
Invented by John Backus, describes syntax of Algol 58.  BNF is equivalent to a context-free grammar.

in BNF, abstractions are used to represent classes of syntactic structures. Each abstraction acts like syntactic variables (aka nonterminal symbols or terminals.)
Terminals are lexemes or tokens
Rule structure: every rule has a left-hand side, and a right hand side
- left hand side LHS is a nonterminal
- right hand side RHS is a string of terminals, string of nonterminals, or both

Nonterminals are often in angle brackets.
Example:
`<ident_list> <- identifier | identifier <ident_list>`
`<if_stmt> -> if <logic_expr> then <stmt>

a grammar is finite, non-empty set of rules.

Each abstraction can have more than one RHS
`<stmt> >- <single_stmt>`
	 `  |  <stmt_list> end`

recursion is allowed
`<ident_list> -> ident`
			`| ident, <ident_list>`

a derivation is a repeated application of rules, until you get only terminal symbols, it cannot be broken down any further.
![[Pasted image 20250115130038.png]]

A program can be broken down into statements
statements can be broken into a single statement, or into one statement and multiple statements. Essentially, can turn into an arbitrary number of single statements.
Each single statement is `<var>=<expr>`
there's four variables
each expression is either the addition or subtraction of two terms 
each term is a variable of constant

This exactly what we did to prove a string is in a context-free grammar in CSC 320
![[Pasted image 20250115130426.png]]


### Derivations
Each string of symbols in a derivation is a sentential form
a sentence is a sentential form that only has terminal symbols.
A leftmost derivation is when you always expand the leftmost nonterminal. This is not always required, it's just a convention.

Note that derivations can be shown in a parse tree:
![[Pasted image 20250115131642.png]]

If a grammar lets you generate a sentential form with two or more different parse trees, it's ambiguous. This is generally not good, and extra rules have to be provided to the compiler to prevent this.
![[Pasted image 20250115131848.png]]
In this case both trees lead to the same result but arrived there in different ways. In the left example, the subtraction expression appears as though it should be performed first, while in the right tree the \* looks like it should be done first.

In order to get around this ambiguity, we add a rule:
- The parse tree indicates the precedence of operators