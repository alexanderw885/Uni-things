We want to compare two genes, and see how similar they are. How might we do this?
- **Hamming sequence:** Compare the two strings directly. Add 1 to the score for each matching character. Problem: this only works if you perfectly aligned. Nearly identical strings will get 0 if mismatched by one.
- **Longest substring:** Let the length of the longest matching substring be the score. Problem: one insertion could potentially half the score
- **Counting shared k-mers:** Count the k-mers in each string, and compare the counts. Take the minimum count of each shared k-mer. This is used in some contexts, but you lose any sense of ordering.

What if we made an approach where we can slide, or shift symbols? What if we try to maximize matches, but allow some holes or gaps in each string?

This is what the process might look like from start to finish:
![[Pasted image 20250923113934.png]]

Let's try to define this: for two strings v, w, the alignment of v and x is a two row matrix such that:
- the first row contains v in order
- the second row contains w in order
- each row may contain a "gap symbol", "-"
- no column has two gap symbols.

Relative to the first string, there are four operations for each column
- match
- mismatch
- insertion of a gap into the string
- Deletion, adding a gap to the other string

We want to find the *longest common subsequence* between the two strings

Let's take a detour to the graphs. Say you want to traverse from a to b, in the path with the highest weight:
![[Pasted image 20250923115108.png]]
This is a good dynamic programming problem, though we do need to be careful that there's no cycles.

We want to find the longest path in a directed acyclic graph (DAG). This is a well-defined, well-known problem with solutions. We can convert our sequence alignment problem into a longest path problem.
- let a match or a mismatch be a move down-right
- let an insertion be a move right
- let a deletion be a move down.
We can draw this s a graph as follows:, with the first string on the side and the second string on the top
![[Pasted image 20250923115349.png]]
This is the *alignment network* of these two strings.

We add weights to every match, and leave every other edge as a zero. For this graph, we would weight it as follows:
![[Pasted image 20250923115544.png]]

Now we know the best value, but how do we then go back and find the path used?
When we're calculating the weights, you also store which node you got that best value from. Then, once you've found the max value, you can backtrack from the endpoint back to the start. This will find *a* path, not necessarily *the path*.

### Global alignment

Typically, we not only reward matches, but also penalize mismatches and deletions/insertions.
match: $+1$
mismatch: $-\mu$
insertion/deletion: $-\sigma$

Now, we want to find an alignment that maximizes the score for our two parameters.
This is just a slight modification to the algorithm. Now, all vertical and horizontal edges have the weight $-\sigma$, and all diagonal edges that don't match have weight $-\mu$.
![[Pasted image 20250924114119.png]]
We can take it even further, and vary the weights depending on the exact type of matrix. 

We can go even further, and make a penalty matrix depending on exactly what the mismatch is. Here's a penalty graph for amino acids:
![[Pasted image 20250924114301.png]]

We can still use the exact same algorithm, and the graph will be the same shape. The only differences this causes are in the weights of the edges.
### Local alignment
Used more often than global alignment.
Let's say there's a part of genes that are well preserved through evolution, or we want to fund a specific short sequence. You need local alignment for these.
Here, we don't want to penalize insertions/deletions and mismatches differently.
![[Pasted image 20250924115510.png]]
The top alignment might get a better score, but the bottom alignment is much closer to what we're looking for. This shows that the ideal result may be far from the highest scoring result.
![[Pasted image 20250924115630.png]]
You can see in this case there's a large amount of horizontal lines, a very diagonal section, then a large amount of vertical lines. These are from aligning a shorter string with a longer one.
All we need to do, is not penalize these local alignment sections.
### Affine alignment
![[Pasted image 20250924120338.png]]
Of these two, the right is better. Insertions and deletions are relatively rare, so one large gap is more likely than multiple smaller gaps. We can add an affine penalty: 
- gap opening penalty $\sigma$
- gap extension penalty $\epsilon$
Sigma will be much larger than epsilon, to discourage small gaps.
Compared to all the previous changes, this one will be slightly more complex.
Solution 1: Add a very large amount of new edges to the alignment graph to add these large jumps. This is a pretty bad idea, as it massively increases runtime.

A better solution is to add a 3rd dimension to the graph.
- One dimension only has insertions
- One only has deletions
- One only has matches and mismatches
![[Pasted image 20250924120756.png]]
We do need to add edges to traverse between these three separate graphs, but it's manageable compared to the other solution.
Every time we leave the matches graph, we add the penalty  $\sigma$, and add $\epsilon$ to every edge in the other graphs.
### Multiple alignment
Now we have $t$ strings, and we want to align them. Trying to use the same algorithm but in $t$ dimensions is exponentially harder to do. We need to find another method.
For this, we use a greedy alignment.
1. Find optimal alignment for each pair of strings
2. find a way to combine these alignments into a multiple alignment
This still works pretty well in practice, even though in theory there's lots of cases where it won't