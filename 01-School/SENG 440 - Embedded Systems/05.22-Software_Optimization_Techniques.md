Compilers aren't perfect, and when you have very limited  data memory/space, you need to be very careful about how big and efficient your program is.
### pipelining
pipelining makes programs run much faster, but has to stop and wait when there's an instruction that depends on the results of a previous instruction that hasn't finished yet. These dependencies are called "true dependencies"
![[Pasted image 20250522091410.png]]
x86 architecture is "out of order", meaning in cases like this, it can reorder the instructions to reduce these "bubble". ARM is in-order, so we have to do the reordering for it.
![[Pasted image 20250522091533.png]]
### Horizontal Processors
also known as Very Long Instruction Word (VLIW) Processors.
in a VLIW, two or more instructions run in parallel. each unit reads in its own two arguments, and writes back the result.
Just like with pipelining, true dependencies result in slower operations and less parallelism.
### Profile-driven compilation
cycle of performance tuning: Compile, Profile, Recompile.
We want to identify the most used part of the program, and optimize that part as much as possible. you can get the profile information with the following steps:
1. Compile your code with the `-pg` flag
2. run the program, this will create the profile information file `gmon.out`
3. use the command `gprof`. You *don't* need to specify the file as an argument.
### software pipelining
let's look at an example in C:
```c
vecdiv(float a[], int size) {
	int i;
	float a_temp;
	
	for(int i=0; i<size; i++) {
		a_temp = a[i];
		a[i] = a_temp / 3.14;
	} /*JMP command at end of loop*/
}
```
This code has a LOAD command, followed by a DIVIDE. the second instruction can't happen until the first is finished, so there isn't much pipelining here. We can fix this by separating the LOAD and DIVIDE into different iterations of the loop
```c
vecdiv(float a[], int size) {
	int i;
	float a;
	
	// prologue
	a_temp = a[0];
	
	// kernel
	for(int i=0; i<size-1; i++) {
		a[i] = a_temp / 3.14;
		a_temp = a[i+1];
	}/*JMP command at end of loop*/
	
	// epilogue
	a[size-1] = a_temp / 3.14;

}
```
Now in each loop iteration we're dividing one value, and loading a different one, there's no dependencies. While this is faster, it does make programs harder to read. It also uses more registers.

### Loop Unrolling
performing multiple iterations in one loop. Let's look at the example code again:
```c
vecdiv(float a[], int size) {
	int i;
	float a_temp;
	
	for(int i=0; i<size; i++) {
		a_temp = a[i];
		a[i] = a_temp / 3.14;
	} /*JMP command at end of loop*/
}
```
we could unroll it by incrementing `i` by 2 each loop
```c
vecdiv(float a[], int size) {
	int i;
	float a_temp;
	
	for(int i=0; i<size; i+=2) {
		a1_temp = a[i];
		a2_temp = a[i+1];
		a[i] = a1_temp / 3.14;
		a[i+1] = a2_temp / 3.14;
	} /*JMP command at end of loop*/
}
```
in this case, we were able to pipeline the code better as well.
pipelining and loop unrolling are similar, but do have some differences
- Software pipelining needs less code
- Loop Unrolling can cause more cache misses
- Real-time response can't be controlled with pipelining
- Real-time response decreases with loop unrolling
- Software pipelined loops cannot be interrupted
### Grafting
Grafting is duplicating code segments that are likely to be repeated to reduce the number of conditionals, which add bubbles into pipelines.
![[Pasted image 20250522104516.png]]
In this example, we're almost always going to repeat this segment, so we can repeat it in the code to reduce the number of interrupts:
![[Pasted image 20250522104618.png]]
This technique is very similar to loop unrolling.
### Misc. Techniques
Operator strength reduction:
	replace expensive operators with cheaper ones. Instead of dividing 10 things by the same value, get the reciprocal of that value and multiply it 10 times instead, as division is very expensive.
Move externals and reference parameters to local:
	copy external variables to local variables, and then write the results back after. external variables can't be written to registers, so they're much slower to work on.
Remove function calls:
	less jumps means faster code, though repeated code does increase file size.
	You can inline everything by adding the flag `O3` to `gcc` compilation, or using pragmas to inline specific functions.
	`#pragma inline`
Use boolean expressions instead of comparisons
	In C, `true` is a non-zero value, and `false` is zero. In some cases, a check like `(E & 1)` might be faster than `(E == 1)`
	
### Interruptible and non-interruptible loops
JUMP operations are either interruptible or non-interruptible. We need to have some interruptible sections of code to make sure we have real-time response, but sometimes we want to make sure no interrupts occur in a segment. We can do this in C with pragmas.
the ATOMIC pragma means this function cannot be interrupted.
let's update our software pipelined example to be non-interruptible:
```c
#prama ATOMIC
vecdiv(float a[], int size) {
	int i;
	float a;
	
	// prologue
	a_temp = a[0];
	
	// kernel
	for(int i=0; i<size-1; i++) {
		a[i] = a_temp / 3.14;
		a_temp = a[i+1];
	}/*JMP command at end of loop*/
	
	// epilogue
	a[size-1] = a_temp / 3.14;

}
```

